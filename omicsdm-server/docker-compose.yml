services:
    # api:
    #     build: .
    #     depends_on:
    #         - db
    #     ports:
    #         - 5000:5000
    #     env_file:
    #         - .env
    #     #restart: always

  db:
    image: postgres:13-alpine
    volumes:
        - postgres-data:/var/lib/postgresql/data/
    environment:
        - POSTGRES_PASSWORD=password

  sonarqube:
      image: sonarqube:25.3.0.104237-community
      # image: sonarqube:9.9.8-community
      ports:
          - "9003:9000"
          - "9094:9092"

  # watch out minio crashes the vscode ssh connection 
  # when accessing the minio UI
  s3bucket:
    image: bitnami/minio:2024.12.18-debian-12-r0
    ports:
      - 9000:9000
      - 9001:9001
    tty: True
    healthcheck:
      test: |
        curl -Is http://s3bucket:9000/minio/health/live | head -n 1 | grep 200
      interval: 5s
      timeout: 5s
      retries: 10
    environment:
      - MINIO_ROOT_USER=admin
      - MINIO_ROOT_PASSWORD=12345678
      - MINIO_DEFAULT_BUCKETS=bucketdevel3tropal
      - MINIO_REGION_NAME=us-east-1
    restart: unless-stopped
    networks:
      - sp-net

  # s3bucket:
  #   image: localstack/localstack
  #   ports:
  #     - "4566:4566" # LocalStack Gateway port
  #     - "4572:4572" # S3 default port
  #   environment:
  #     - SERVICES=s3
  #     - DEBUG=1
  #     - DATA_DIR=/tmp/localstack/data
  #     - DEFAULT_REGION=us-east-1
  #     - AWS_ACCESS_KEY_ID=test
  #     - AWS_SECRET_ACCESS_KEY=test
  #   networks:
  #     - sp-net

  shinyproxy:
    image: openanalytics/shinyproxy:3.1.1
    container_name: shinyproxy
    environment:
      DOCKER_IMG: ${DOCKER_IMG}
      DOMAIN: ${DOMAIN}:8080
      KC_INTERNAL_URL: keycloak:8080
      # DOMAIN: omicsdm.cnag.dev/auth
      # KC_INTERNAL_URL: omicsdm.cnag.dev/auth
      KC_REALM: ${KC_REALM}
      KC_CLIENT_ID: ${KC_CLIENT_ID}
      KC_CLIENT_SECRET: ${KC_CLIENT_SECRET}

    ports:
      - 3830:8080
      # - 3830:3830
    volumes:
      - /run/docker.sock:/var/run/docker.sock:ro
      - ./shinyproxy/application.yml:/opt/shinyproxy/application.yml:ro
      # - ./shinyproxy/shinyproxy.log:/opt/shinyproxy/shinyproxy.log:rw
    group_add:
      - 999 # getent group docker | cut -d: -f3
    networks:
      - sp-net
    restart: unless-stopped

  keycloak-db:
    image: postgres:16.1-alpine3.18
    container_name: kc-db
    environment:
      POSTGRES_DB: ${KC_DB}
      POSTGRES_USER: ${KC_DB_USER}
      POSTGRES_PASSWORD: ${KC_DB_PW}
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "psql -U $KC_DB_USER -d $KC_DB -c 'SELECT 1' || exit 1"]
      interval: 10s
      timeout: 10s
      retries: 3

  keycloak:
    container_name: keycloak
    image: quay.io/keycloak/keycloak:20.0 # version > 20.0 query-groups not working # versions > 24 are running on the client into a login loop
    depends_on:
      - keycloak-db
    environment:
      DB_VENDOR: postgres
      DB_ADDR: postgres
      DB_DATABASE: keycloak
      DB_USER: ${KC_DB_USER}
      DB_PASSWORD: ${KC_DB_PW}
      KEYCLOAK_ADMIN: ${KC_ADMIN_USER}
      KEYCLOAK_ADMIN_PASSWORD: ${KC_ADMIN_PW}
      KC_PROXY: edge
      KC_HOSTNAME_STRICT: false
      # KC_HOSTNAME_PATH: /auth
      # KC_HOSTNAME_URL: http://${DOMAIN}:8080
      KC_HOSTNAME_URL: http://${DOMAIN}:8080
      # KC_HOSTNAME_ADMIN_URL: http://${DOMAIN}
      KC_HOSTNAME_ADMIN_URL: http://${DOMAIN}:8080
      KC_HEALTH_ENABLED: true
    volumes:
      - ./realm-export.json:/opt/keycloak/data/import/realm-export.json
    restart: unless-stopped
    command: ${KC_CMD}
    healthcheck:
      test: curl localhost:8080/health | grep -q "UP"
      interval: 10s
      timeout: 10s
      retries: 5
    ports:
      - 8080:8080
    networks:
      - sp-net

  rabbitmq:
    image: rabbitmq:3.13.0-rc.4-management-alpine
    ports:
        - 5672:5672
        - 15672:15672
    environment:
        - RABBITMQ_DEFAULT_USER=admin
        - RABBITMQ_DEFAULT_PASS=admin1234

  redis:
    image: redis:7.2.4-alpine
    ports:
        - 6379:6379

  # celery-worker:
  #   build:
  #     context: .
  #     # target: dev
  #     args:
  #       - IGNORE_CACHE_FROM_HERE=${IGNORE_CACHE_FROM_HERE}
  #   depends_on:
  #     - rabbitmq
  #     - redis
  #   volumes:
  #     - ./omicsdm_server/server/config/config.py:/usr/src/app/server/config/config.py
  #     - /var/run/docker.sock:/var/run/docker.sock
  #     - ./omicsdm_server/server/apis/analysis.py:/usr/src/app/server/apis/analysis.py
  #   command: [
  #     celery,--config,server.config.celeryconfig,
  #     -A,server.app.celery,worker,--loglevel=info,-E,
  #     --concurrency=4,-O,fair
  #   ]

  flower:
    image: mher/flower:2.0.1
    environment:
        - CELERY_BROKER_URL=amqp://admin:admin1234@rabbitmq:5672//
    ports:
        - 5557:5555
    depends_on:
        - rabbitmq
    command: celery flower --broker_api=http://admin:admin1234@rabbitmq:15672/api/

  # s3fs:
  #   privileged: true
  #   image: efrecon/s3fs:1.94
  #   restart: always
  #   environment:
  #     - AWS_S3_BUCKET=bucketdevel3tropal
  #     - AWS_S3_ACCESS_KEY_ID=admin
  #     - AWS_S3_SECRET_ACCESS_KEY=12345678
  #     - AWS_S3_URL=http://s3bucket:9000
  #   volumes:
  #   # This also mounts the S3 bucket to `/mnt/s3data` on the host machine
  #     - /mnt/s3data:/opt/s3fs/bucket:shared

  # needed to distribute the docker images to the virtual machines
  # docker-registry:
  #   image: registry:2
  #   container_name: docker-registry
  #   restart: unless-stopped
  #   environment:
  #     REGISTRY_AUTH: htpasswd
  #     REGISTRY_AUTH_HTPASSWD_PATH: /auth/htpasswd
  #     REGISTRY_AUTH_HTPASSWD_REALM: Local Registry Realm

  #     # REGISTRY_HTTP_TLS_CERTIFICATE: /certs/docker.${DOMAIN}.pem
  #     # REGISTRY_HTTP_TLS_KEY: /certs/docker.${DOMAIN}-key.pem

  #   volumes:
  #     - ./docker-registry_data/data:/var/lib/registry
  #     - ./docker-registry_data/auth:/auth:ro
  #     - ./nginx_mountpoint/certs:/certs
  #   ports:
  #     - 5000:5000

  test:
    image: alpine:latest
    container_name: alpine
    volumes:
      - s3data:/mnt/s3data
    command: sleep infinity # Keeps the container running
    stdin_open: true # Optional: Allows interaction with the container via `docker exec`
    tty: true # Optional: Allows a pseudo-TTY for interactive shell

volumes:
  postgres-data:
  docker-registry_data:
  s3data:
    driver: local
    driver_opts:
      type: none
      device: /home/ivo/projects/bioinfo/cnag/repos/omicsdm-server/s3fs_mountpoint
      o: bind

networks:
  sp-net:
    # driver: bridge
    # ipam:
    #   config:
    #     - subnet: 192.168.100.0/24